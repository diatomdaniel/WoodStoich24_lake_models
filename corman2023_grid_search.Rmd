---
title: "Corman et al Grid Search"
author: "Daniel Gschwentner"
date: "2024-07-22"
output: html_document
  toc: true
  theme: united
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T, message = F, warning = F)
```


## Notes

- included modelled zmix from surface area and DOC following Kelly et al 2018; had to impute DOC for 1 lake using median DOC of all lakes.

-   **Update: 26-July-2024; I double checked the model code and units are volumetric, i.e. all GPP/P/N are reported as mg m^-3^ this should match volumetric measurments in Corman et al data set.**

- ** idea for model improvement: instead of using median of all GPP and load data from Corman data set, aggregate values on __monthly__ basis; this would improve our sample size and reveal more patterns **

    -   Need to double check model units, currently in mg Cm^-2^ I believe; need to multiply with lake depth to obtain mg C m^-3^ . **Confirm this with CO!**

-   Problem of nutrient loads:\
    Corman et al data set contains volume-weighted loads in ug P/N (m^-3^ lake water) day^-1^. Do these need to be converted to a different unit format?\
    Current approach is as follows: (1) calculate lake volume as depth \* surface area from T1 in Corman paper, (2) calculate total ug P and N supplied to lake by multiplying loads with lake volume, (3) divide total input by the volume of the chemostat model to get inflow N and P concentrations/

-   I didn't use a very sophisticated approach to get median GPP and nutrient data from the Corman data set. I just took the median of all values for a give lake. Upon closer inspection, there are observations with nutrient loads but without GPP...it might be wise to filter the data to only include observations for which GPP is present and take the average of these data...

-   Models produce very poor output when compared to median GPP from Corman et al data set; both the Michaelis-Menten and Droop formulations produce low GPP estimates that deviate strongly from the 1:1 line (see figures below).

    -   The Corman et al data set has a relatively narrow range of values for GPP and TN/TP loads.\
        Median GPP only ranges from 0.001 to 0.93 mg C L^-1^ day^-1^ with a median and sd of 0.1 and 30 mg C L^-1^ day^-1^. In 11 out 14 instances, the sd of GPP is greater than the median of GPP. TN and TP loads are much more variable with sd of 25.94 and 0.51 mg N/P m^-3^. Although there are relatively strong relationships between nutrient loads and median GPP (R^2^ of 0.41 and 0.71 for TN and TP), this relationship is not captured by the our models.

        -   Taking the average of the Corman GPP data doesn't really tell us about the behavior of these lakes or how it relates to the models. In 11 out 14 instances the standard deviation of the lake GPP exceeds the median value which is pretty unhelpful if you're trying to say anything about anything.

-   The Corman data presents includes nutrients loads but not inflow volumes....our models simulate chemostat behavior where inflow and outflow are perfectly balanced...\
    is it safe to assume that inflow loads from Corman et al are equivalent to inflow concentrations in our model or does some conversion need to take place? Corman et al do not include discharge into lakes in their data set (as far as I can tell).\
    I am curious whether the chemostat behavior of our models in contrast to the dynamic behavior of actual lakes is causing disagreement with modeled and measured rates of GPP?

-   The "best parameter" values always include a very small $K_P$ value which indicates that the models are super sensitive to P-uptake, and that P is ultimately limiting in the model...this agrees with my sensitivity analysis which also emphasize the importance of P and half-saturation constants. In contrast, cell quotas and uptake rates are less important. Uptake rates are probably not relevant in these models as they provide an advantage under fluctuating resource supply while our chemostat models have fixed/constant resource supply.

-   I think one of the reasons that the P-parameters are consistently identified as the "best" parameters is that TP loads are low compared to TN loads in the Corman et al data set.

## Introduction

Code to conduct parameter value grid search for lake ecosystem models. Models are fit to [Corman et al 2023](https://aslopubs.onlinelibrary.wiley.com/doi/full/10.1002/lno.12449) GPP data across measured TN and TP a range of parameter values. The fit of the model and its parameters is determined by calculating the root-mean-square error (RMSE) between the model estimate and the known parameter values

$$

RMSE = \sqrt{mean((X_{known} - X_{measured})^2)}

$$

Basically, the parameter set which minimizes the RMSE is selected as the "optimal" parameter set and the model(s) are re-fit. Then the model output is compared to the real world data.

## Setup

```{r setup environment and load traits, include=F, warning=F, message=F, echo = F}
pck <- c("deSolve", "tidyverse", "cowplot", "ggsci", "ggpubr", "ggtern", "patchwork")
lapply(pck, require, character.only = T)
theme_set(theme_cowplot() + 
            theme(legend.justification = "center",
                  legend.position = "bottom", 
                  legend.text = element_text(),
                  legend.title = element_text()))
# load ODE models 
# saved in external files for convenience
# Michalis-Menten model
source("models/mich_single_noLight_calc_zmix.R") # michaelis menten kinetics, one algae species; model 1 in Carly's framework
# Droop model
source("models/droop_single_noLight_calc_zmix.R") # droop model, one algae species; model 3 in Carly's framework

# set up scenarios
times <- 1:500

# load data set
corman <- read_csv("data4input/Corman2023 metabolism result.csv")

```

### Unit conversions

-   Loads from Corman et al 2023 are in ug m^-3^. Loads are divided by 1000 $\frac{ug}{mg}$ to convert to mg m^-3^ which are required for the model.

-   GPP in Corman et al 2023 are presented in mg O~2~ L^-1^ day^-1^. The models produce output of mg C L^-1^. GPP from Corman et al GPP data are transformed to mg C L^-1^ day^-1^ using the ratio of moles C to moles O~2~ of $\frac{12 mg C}{12 mg O2}$ = 0.375.

```         
"Acton", "EastLong", "Feeagh", "Harp", "Langtjern", "Lillinonah", "Lillsjoliden",   "Mangstrettjarn", "Mendota", "Morris", "Ovre", "Struptjarn", "Trout", "Vortsjarv"     
```

```{r edit corman et al data set to get correct units}
# corman data lake volumes
# no DOC for Lillinonah! used median DOC of the data set = 11.8
corman.vol <- tibble(
  Lake = c("Acton", "Crampton", "EastLong", "Feeagh", "Harp", "Langtjern", 
           "Lillinonah", "Lillsjoliden", "Mangstrettjarn", 
           "Mendota", "Morris", "Nastjarn", "Ovre", "Struptjarn", "Trout", "Vortsjarv"),
  Depth_m = c(3.9, 5.03, 4.04, 14.50, 13.30, 2, 13, 3.8, 5.3, 
              12.80, 2.42, 4.20, 4, 3.80, 14.60, 2.80),
  SA_km2 = c(2.5, 0.26, 0.03, 3.92, 0.71, 0.23, 6.26, 0.01, 0.02, 
             39.60, 0.06, 0.01, 0.05, 0.03, 15.70, 270), 
  DOC_mgL = c(4.3, 4.6, 10.6, 5.6, 5.2, 11.8, 11.8, 15.5, 11.9, 4.7, 17.3, 8.2, 23.2, 19.9, 2.8, 11.9)) %>%
  mutate(volume_m3 = SA_km2 * 1e6 * Depth_m)
# load data
corman2 <- corman
# select columns needed
corman2 <- corman2 %>%
  select(Lake, DateTime, GPP, TN_load, TP_load) %>%
  drop_na() %>%
  mutate(GPP = GPP * 0.375, # convert from O2 to C: 12 mg per mole C/32 mg per mole O2
         TN_load = TN_load/1000, 
         TP_load = TP_load/1000) %>% # divide by 10^3 bc. Corman et al data is in units ug m^-3 and we need mg m^-3
  # merge(., corman.vol, by = "Lake") %>%
  # mutate(TN_in = TN_load * volume_m3, 
  #        TP_in = TP_load * volume_m3) %>%
  # # caclulate "new" loads for the model
  # mutate(TN_load = TN_in/(2 * 1e6), 
  #        TP_load = TP_in/(2 * 1e6)) %>%
  merge(., corman.vol, by = "Lake") %>%
  group_by(Lake) %>%
  summarize(GPP = median(GPP), 
            TN_load = median(TN_load),
            TP_load = median(TP_load),
            SA = median(SA_km2),
            DOC_mgL = median(DOC_mgL),
            z_m = median(Depth_m))
# add calculated zmix
corman2$zmix <- 10^(-0.515 + log10(corman2$DOC_mgL) + 0.115 * log10(2 * sqrt(corman2$SA/pi + 0.991)))
# if zmix > z, set zmix to z; this is done in code

```

overview figure of Corman et al GPP data and relationship to nutrient loads; note the lack of relationship at low loads indicating decoupling of supply and production (the models don't capture these data well but that is okay because they have no mechanisms to do so; models are very dependent on loads to model GPP)

```{r plot corman data for overview ,dpi = 500, fig.width=10, fig.height=3}

c1 <- corman2 %>%
  ggplot(aes(GPP)) + 
    geom_density(col = "black", fill = "grey80") + 
  geom_vline(xintercept = quantile(corman2$GPP, c(0.0275, 0.5, 0.975)), 
             col = "red", lty = "dashed") + 
  labs(x = expression("GPP mg C L"^-1 ~ "day"^-1), 
       y = "Density")

c2 <- corman2 %>%
  ggplot(aes(TP_load, GPP)) + 
  geom_point() + 
  labs(x = expression("TP load mg P m"^-3 ~ "lake water day"^-1),
    y = expression("GPP mg C L"^-1 ~ "day"^-1)) 

c3 <- corman2 %>%
  ggplot(aes(TN_load, GPP)) + 
  geom_point() + 
  labs(x = expression("TN load mg N m"^-3 ~ "lake water day"^-1),
    y = expression("GPP mg C L"^-1 ~ "day"^-1)) 

c1 + c2 + c3 + plot_layout(ncol = 3)

```


### Create grid of parameter values

Ranges: these are based on ranges observed in the Edwards et al data set for phytoplankton. I expanded the ranges a little to encompass a wider range of possible scenarios.

-   $K_P$ = 1 to 20 ug L^-1^

-   $K_N$ = 10 to 50 ug L^-1^

-   $V_{maxP}$ = 0.1 to 1 mg P (mg C)^-1^

-   $V_{maxN}$ = 0.1 to 1 mg N (mg C)^-1^

-   $Q_{minP}$ = 0.01 to 0.5 mg P (mg C)^-1^

-   $Q_{minN}$ 0.01 to 0.5 mg N (mg C)^-1^

```{r parameter grids}
# michaelis menten grid
grid <- expand.grid(
  KP1 = seq(1, 20, ),
  KN1 = seq(10, 50, 5), 
  minQN1 = seq(0.1, 1, 0.1),
  minQP1 = seq(0.1, 1, 0.1)
)

# repeat grid nrow(corman2) times
grid.new <- grid %>% 
  slice(rep(1:n(), each = nrow(corman2)))

# add in corman2 data
grid.new$Lake <- rep(corman2$Lake, nrow(grid))
grid.new$GPP <- rep(corman2$GPP, nrow(grid))
grid.new$TN_load <- rep(corman2$TN_load, nrow(grid))
grid.new$TP_load <- rep(corman2$TP_load, nrow(grid))
grid.new$SA <- rep(corman2$SA, nrow(grid))
grid.new$DOC_mgL <- rep(corman2$DOC_mgL, nrow(grid))
grid.new$z_m <- rep(corman2$z_m, nrow(grid))

# droop grid
grid.droop <- expand.grid(
  KP1 = seq(1, 20, 1),
  KN1 = seq(10, 50, 5), 
  minQN1 = seq(0.1, 1, 0.1),
  minQP1 = seq(0.1, 1, 0.1),
  upP1 = c(0.1, 0.4, 0.8),
  upN1 = seq(0.05, 1, 1.5)
)

# repeat grid nrow(corman2) times
grid.droop.new <- grid.droop %>% 
  slice(rep(1:n(), each = nrow(corman2)))

# add in corman2 data
grid.droop.new$Lake <- rep(corman2$Lake, nrow(grid.droop))
grid.droop.new$GPP <- rep(corman2$GPP, nrow(grid.droop))
grid.droop.new$TN_load <- rep(corman2$TN_load, nrow(grid.droop))
grid.droop.new$TP_load <- rep(corman2$TP_load, nrow(grid.droop))
grid.droop.new$SA <- rep(corman2$SA, nrow(grid))
grid.droop.new$DOC_mgL <- rep(corman2$DOC_mgL, nrow(grid.droop))
grid.droop.new$z_m <- rep(corman2$z_m, nrow(grid.droop))

```

```{r set up phytoplankton traits, message=F, warning=F}
### averages

## michaelis-menten model for mean phytoplankton traits
params.mich <- c(
  # lake parameters
  SA= NA,		# lake surface area in km2
  #zmix = 2, # lake mixing depth in m
  Pin = NA, # P inflow concentration in mg P m^-3
  Nin = NA, # N inflow concentration in mg N m^-3
  DOC = NA,
  z = NA,
  
  #light parameters
  I0 = 400, # incident light
  kBg= 0.1,		# background light attenuation (m-1)/(g C m-3); 0.1-5.6 from Jager & Diehl
  kA=0.0003, # algal light attenuation (m-1)/(mg C m-3); 0.0003 from Jager & Diehl

  # algae physiology parameters
  umax1 = 0.665,
  lA=0.1,			# mortality rate day-1
  v=0.1,			# m d-1; sinking loss of algae
  KLight = 166.53, # light half sat constant 
  KP1 = NA, # phosphorus half sat constant in mg P m^-3 f
  QP1 = NA, # algae cell P quota in mg P mg^-1 C^-1
  KN1 = NA, # nitrogen half sat constant in mg N m^-3 
  QN1 = NA # algae cell N quota in mg N mg^-1 C^-1 
)
names(params.mich) <- c("SA", "Pin", "Nin", "I0", 
                        "kBg", "kA", "umax1", "lA", "v", 
                        "KLight", "KP1",  "QP1", "KN1",  "QN1")
names(params.mich)
params.mich <- unlist(params.mich)

## droop model for mean phytoplankton traits

params.droop <- c(
  # lake parameters
  SA= NA,		# lake surface area in km2
  #zmix = 2, # lake mixing depth in m
  Pin = NA, # P inflow concentration in mg P m^-3
  Nin = NA, # N inflow concentration in mg N m^-3
  DOC = NA,
  z = NA,

  # light parameters
  I0 = 400, # surface light
  kBg= 0.1,		# background light attenuation (m-1)/(g C m-3); 0.1-5.6 from Jager & Diehl
  kA=0.0003, # algal light attenuation (m-1)/(mg C m-3); 0.0003 from Jager & Diehl
 
  # algae physiology parameters
  umax1 = 0.665,
  lA=0.1,			# mortality rate day-1
  v= 0.1,			# m d-1; sinking loss of algae
  KLight = 155.53, # light half sat constant 
  KP1 = NA, # phosphorus half sat constant in mg P m^-3 f
  minQP1 = NA, # algae cell P quota in mg P mg^-1 C^-1 f
  upP1 = NA, # max uptake rate P per day in mg P mg C^-1 day^-1 
  KN1 = NA, # nitrogen half sat constant in mg N m^-3 
  minQN1 = NA, # algae cell N quota in mg N mg^-1 C^-1 f
  upN1 = NA # max uptake rate N per day in mg N mg C^-1 day^-1 
)



names(params.droop) <- c("SA", "Pin", "Nin", "I0", "kBg", "kA",
                             "umax1", "lA", "v", "KLight", 
                             "KP1", "minQP1", "upP1", "KN1",
                             "minQN1", "upN1")
names(params.droop)
params.droop <- unlist(params.droop)

```

## Run models

### Michaelis-Menten model

Run the MM model across all grid values and return output; combine estimated GPP with known GPP and calculate RMSE.\
This code chunk takes \>1hr to run so I've saved the output to an external file for easier loading. It is all stored on the Github repo so you should be able to load it easily.

```{r run MM across input grid}
#takes over an hour to run!!
# (start <- Sys.time())
# mm.grid <- lapply(1:nrow(grid.new), function(i){
#   # indexing
#   params.mich["SA"] = grid.new[i, "SA"]
#   params.mich["DOC"] = grid.new[i, "DOC_mgL"]
#   params.mich["z"] = grid.new[i, "z_m"]
#   params.mich["KP1"] = grid.new[i, "KP1"]
#   params.mich["KN1"] = grid.new[i, "KN1"]
#   params.mich["QP1"] = grid.new[i, "minQP1"]
#   params.mich["QN1"] = grid.new[i, "minQN1"]
#   params.mich["Pin"] = grid.new[i, "TP_load"]
#   params.mich["Nin"] = grid.new[i, "TN_load"]
#   # starting values
#   y <- c("A1" = 100, "P" = grid.new[i, "TP_load"], "N" = grid.new[i, "TN_load"])
#   run <- ode(y, times, parms = params.mich, func = mich.single)
#   return(run[max(times),])
# })
# # convert to df
# mm.grid <- do.call(rbind, mm.grid)
# mm.grid <- as_data_frame(mm.grid)
# (end <- Sys.time())
# time.elapsed <- (end - start)/60/60
# print(paste0("Time elapsed = ", time.elapsed, " hours!"))

# # grids take too long to run, gonna save to r data file and reload for convenience
# save(mm.grid,file = "temporary_model_files/corman2023_MM_gridsearch.Rdata")
#save(mm.grid,file = "temporary_model_files/corman2023_MM_gridsearch_zmix.Rdata")
load("temporary_model_files/corman2023_MM_gridsearch_zmix.Rdata")
# add to grid
grid.new$est_GPP <- mm.grid$A1
 
```

Figure shows histogram for RMSE scores for all scenarios; red lines show 95% conf. intervals and median RMSE. For some bizarre reason the 50th and 97.5th quantiles are the same.
The low RMSE values are not actually indicative of good model fit; the estimated GPP is just so low that errors are relatively small.

```{r calculate RMSE for MM}

# add ID label to group
grid.new$group.ID <- rep(1:nrow(grid), each= nrow(corman2))

# calculate RMSE
grid.new.rmse <- grid.new %>%
  group_by(group.ID, KP1, KN1, minQN1, minQP1) %>%
  summarise(RMSE = sqrt( mean((GPP -  est_GPP)^2)  ))
# check distribution of RMSE
hist(grid.new.rmse$RMSE, 
     main = "Distribution of RMSE for \n Michaelis-Menten model", 
     xlab = "RMSE")
abline(v = quantile(grid.new.rmse$RMSE, probs = c(0.025, 0.5, 0.975)), 
       col = "red", lty = "dashed")
# range(grid.new.rmse$RMSE)
# mean(grid.new.rmse$RMSE)
#which.min(grid.new.rmse$RMSE)
# select best parameters
best.parm <- grid.new.rmse[which.min(grid.new.rmse$RMSE), ]
```
Plot below shows RMSE for each scenario; the "best" scenario is highlighted in red.
Note the influence of P-parameters on RMSE. This aligns well with the sensitivity analysis which is nice.

```{r plot RMSE and P for MM, dpi = 500, fig.width=10, fig.height=3}

Kp.rmse <- grid.new.rmse %>%
  ggplot(aes(KP1, RMSE)) + geom_point(alpha = 0.3) + 
  geom_point(inherit.aes = F, data = best.parm, 
             aes(x = KP1, y = RMSE), col = "red", size = 2) + 
  labs(x = expression("K"["P"] ~ " ug L"^-1), y = "RMSE")

Kn.rmse <- grid.new.rmse %>%
  ggplot(aes(KN1, RMSE)) + geom_point(alpha = 0.3) + 
   geom_point(inherit.aes = F, data = best.parm, 
             aes(x = KN1, y = RMSE), col = "red", size = 2) + 
  labs(x = expression("K"["N"] ~ " ug L"^-1), y = NULL)

QP.rmse <- grid.new.rmse %>%
  ggplot(aes(minQP1, RMSE)) + geom_point(alpha = 0.3) + 
   geom_point(inherit.aes = F, data = best.parm, 
             aes(x = minQP1, y = RMSE), col = "red", size = 2) + 
  labs(x = expression("minQ"["P"] ~ "in mg P (mg C)"^-1), y = NULL)

QN.rmse <- grid.new.rmse %>%
  ggplot(aes(minQN1, RMSE)) + geom_point(alpha = 0.3) + 
   geom_point(inherit.aes = F, data = best.parm, 
             aes(x = minQN1, y = RMSE), col = "red", size = 2) + 
  labs(x = expression("minQ"["N"] ~ "in mg N (mg C)"^-1), y = NULL)

Kp.rmse + Kn.rmse + QP.rmse + QN.rmse + plot_layout(ncol = 4)

```

Re-run the model with the best parameters as determined by the grid search above.

```{r re-run MM model with the best parameters}
best.run <- lapply(1:nrow(corman2), function(i){
  # indexing
  params.mich["SA"] = pull(corman2[i, "SA"])
  params.mich["DOC"] =  pull(corman2[i, "DOC_mgL"])
  params.mich["z"] =  pull(corman2[i, "z_m"])
  params.mich["KP1"] = pull(best.parm[1, "KP1"])
  params.mich["KN1"] = pull(best.parm[1, "KN1"])
  params.mich["QP1"] = pull(best.parm[1, "minQP1"])
  params.mich["QN1"] = pull(best.parm[1, "minQN1"])
  params.mich["Pin"] = pull(corman2[i, "TP_load"])
  params.mich["Nin"] = pull(corman2[i, "TN_load"])
  # starting values
  y <- c("A1" = 100, "P" = pull(corman2[i, "TP_load"]), "N" = pull(corman2[i, "TN_load"]))
  run <- ode(y, times, parms = params.mich, func = mich.single)
  return(run[max(times),])
})
# convert to df
best.run <- do.call(rbind, best.run)
best.run <- as_data_frame(best.run)
# combine with original df
best.run <- bind_cols(best.run, corman2)

```

figures show (a) modelled vs. measured GPP, (b) modelled GPP vs TP loads, (c) modelled GPP vs TN loads; dashed line shows 1:1 relationship.

output is not very encouraging but the model does capture the shape of GPP vs. TP/TN loads when loads are high but not when they are low! This might not be that much of an issue as measured GPP is weakly related to low nutrient loads (see figures of Corman GPP values at beginning of Markdown file).

```{r compare output of best model and real world data, dpi = 500, fig.width=13, fig.height=5}

best.run.plt1 <- best.run %>%
  ggplot() + 
  geom_point(aes(GPP, A1, col = log(TP_load)), size = 2.5) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", lwd = 1) + 
  labs(x = expression("Measured GPP mg C L"^-1 ), 
       y = expression("Modelled GPP mg C m"^-1), 
       col = "log(TP load mg m"^-3 ~ ")") 

best.run.plt2 <- best.run %>%
  ggplot() + 
  geom_point(aes(TN_load, A1, col = GPP), size = 2.5) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", lwd = 1) + 
  labs(y = expression("Modelled GPP mg C L"^-1 ), 
       x = expression("TN load mg m"^-3),
       col = expression("Measured GPP mg C m"^-1)) 

best.run.plt3 <- best.run %>%
  ggplot() + 
  geom_point(aes(TP_load, A1, col = GPP), size = 2.5) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", lwd = 1) + 
  labs(y = expression("Modelled GPP mg C L"^-1 ), 
       x = expression("TP load mg m"^-3),
       col = expression("Measured GPP mg C m"^-1)) 

best.run.plt1 + best.run.plt2 + best.run.plt3 + plot_layout(ncol = 3)

# some stats for text
#summary(lm(GPP ~ A1, data =best.run))
#cor.test(best.run$A1, best.run$GPP)

```

### Droop model

Run the MM model across all grid values and return output; combine estimated GPP with known GPP and calculate RMSE.

```{r run droop model across inflow loads and parameter values}

#takes over an hour to run!!
(start <- Sys.time())
droop.grid <- lapply(1:nrow(grid.droop.new), function(i){
  # indexing
  params.droop["SA"] = grid.droop.new[i, "SA"]
  params.droop["DOC"] = grid.droop.new[i, "DOC_mgL"]
  params.droop["z"] = grid.droop.new[i, "z_m"]
  params.droop["KP1"] = grid.droop.new[i, "KP1"]
  params.droop["KN1"] = grid.droop.new[i, "KN1"]
  params.droop["minQP1"] = grid.droop.new[i, "minQP1"]
  params.droop["minQN1"] = grid.droop.new[i, "minQN1"]
  params.droop["upP1"] = grid.droop.new[i, "upP1"]
  params.droop["upN1"] = grid.droop.new[i, "upN1"]
  params.droop["Pin"] = grid.droop.new[i, "TP_load"]
  params.droop["Nin"] = grid.droop.new[i, "TN_load"]
  # starting values
  y <- c("A1" = 100, "P" = grid.droop.new[i, "TP_load"],
         "N" = grid.droop.new[i, "TN_load"],
         "QP1" = 0.015,
         "QN1" = 0.1)
  run <- ode(y, times, parms = params.droop, func = droop.single)
  return(run[max(times),])
})
# convert to df
droop.grid <- do.call(rbind, droop.grid)
droop.grid <- as_data_frame(droop.grid)
(end <- Sys.time())
time.elapsed <- (end - start)/60/60
print(paste0("Time elapsed = ", time.elapsed, " hours!"))

# grids take too long to run, gonna save to r data file and reload for convenience
#save(droop.grid,file = "temporary_model_files/corman2023_droop_gridsearch.Rdata")
save(droop.grid,file = "temporary_model_files/corman2023_droop_gridsearch_zmix.Rdata")
#load("temporary_model_files/corman2023_droop_gridsearch_zmix.Rdata")

# add to grid
grid.droop.new$est_GPP <- droop.grid$A1


```

Calculate RMSE and find best parameters

```{r calculate RMSE and find best parameters for droop model}
# add ID label to group
grid.droop.new$group.ID <- rep(1:nrow(grid.droop), each= nrow(corman2))

# calculate RMSE
grid.droop.new.rmse <- grid.droop.new %>%
  group_by(group.ID, KP1, KN1, minQN1, minQP1, upP1, upN1) %>%
  summarise(RMSE = sqrt((mean(GPP - est_GPP)^2)))
# check distribution of RMSE
# check distribution of RMSE
hist(grid.droop.new.rmse$RMSE, 
     main = "Distribution of RMSE for \n Droop model", 
     xlab = "RMSE")
abline(v = quantile(grid.droop.new.rmse$RMSE, probs = c(0.025, 0.5, 0.975)), 
       col = "red", lty = "dashed")
# range(grid.droop.new.rmse$RMSE)
# mean(grid.droop.new.rmse$RMSE)
#which.min(grid.droop.new.rmse$RMSE)
#which.min(grid.droop.new.rmse$RMSE)
# select best parameters
best.parm.droop <- grid.droop.new.rmse[which.min(grid.droop.new.rmse$RMSE), ]
```



```{r plot RMSE and P for droop, echo = T, dpi = 500, fig.width=13, fig.height=5}

Kp.droop.rmse <- grid.droop.new.rmse %>%
  ggplot(aes(KP1, RMSE)) + geom_point(alpha = 0.3) + 
  geom_point(inherit.aes = F, data = best.parm.droop, 
             aes(x = KP1, y = RMSE), col = "red", size = 1) + 
  labs(x = expression("K"["P"] ~ " ug L"^-1), y = "RMSE")

Kn.droop.rmse <- grid.droop.new.rmse %>%
  ggplot(aes(KN1, RMSE)) + geom_point(alpha = 0.3) + 
    geom_point(inherit.aes = F, data = best.parm.droop, 
             aes(x = KN1, y = RMSE), col = "red", size = 1) + 
  labs(x = expression("K"["N"] ~ " ug L"^-1), y = NULL)

QP.droop.rmse <- grid.droop.new.rmse %>%
  ggplot(aes(minQP1, RMSE)) + geom_point(alpha = 0.3) + 
    geom_point(inherit.aes = F, data = best.parm.droop, 
             aes(x = minQP1, y = RMSE), col = "red", size = 1) + 
  labs(x = expression("minQ"["P"] ~ "in mg P (mg C)"^-1), y = NULL)

QN.droop.rmse <- grid.droop.new.rmse %>%
  ggplot(aes(minQN1, RMSE)) + geom_point(alpha = 0.3) + 
    geom_point(inherit.aes = F, data = best.parm.droop, 
             aes(x = minQN1, y = RMSE), col = "red", size = 1) + 
  labs(x = expression("minQ"["N"] ~ "in mg N (mg C)"^-1), y = NULL)

uP.droop.rmse <- grid.droop.new.rmse %>%
  ggplot(aes(upP1, RMSE)) + geom_point(alpha = 0.3) + 
    geom_point(inherit.aes = F, data = best.parm.droop, 
             aes(x = upP1, y = RMSE), col = "red", size = 1) + 
  labs(x = expression("uptake P mg P (mg C)"^-1), y = NULL)

uN.droop.rmse <- grid.droop.new.rmse %>%
  ggplot(aes(upN1, RMSE)) + geom_point(alpha = 0.3) + 
    geom_point(inherit.aes = F, data = best.parm.droop, 
             aes(x = upN1, y = RMSE), col = "red", size = 1) + 
  labs(x = expression("uptake N mg P (mg C)"^-1), y = NULL)

Kp.droop.rmse + Kn.droop.rmse + QP.droop.rmse + QN.droop.rmse + uP.droop.rmse + uN.droop.rmse + 
  plot_layout(ncol = 6)

```

Re-run model with best parameters

```{r re-run droop  model with the best parameters}
best.run.droop <- lapply(1:nrow(corman2), function(i){
  # indexing
  params.droop["SA"] = pull(corman2[i, "SA"])
  params.droop["DOC"] = pull(corman2[i, "DOC_mgL"])
  params.droop["z"] = pull(corman2[i, "z_m"])
  params.droop["KP1"] = pull(best.parm.droop[1, "KP1"])
  params.droop["KN1"] = pull(best.parm.droop[1, "KN1"])
  params.droop["minQP1"] = pull(best.parm.droop[1, "minQP1"])
  params.droop["minQN1"] = pull(best.parm.droop[1, "minQN1"])
  params.droop["upP1"] = pull(best.parm.droop[1, "upP1"])
  params.droop["upN1"] = pull(best.parm.droop[1, "upN1"])
  params.droop["Pin"] = pull(corman2[i, "TP_load"])
  params.droop["Nin"] = pull(corman2[i, "TP_load"])
  # starting values
  y <- c("A1" = 100, "P" = pull(corman2[i, "TP_load"]), 
         "N" = pull(corman2[i, "TN_load"]),
          "QP1" = 0.015,"QN1" = 0.1)
  run <- ode(y, times, parms = params.droop, func = droop.single)
  return(run[max(times),])
})
# convert to df
best.run.droop <- do.call(rbind, best.run.droop)
best.run.droop <- as_data_frame(best.run.droop)
# combine with original df
best.run.droop <- bind_cols(best.run.droop, corman2)
```

Plot comparison of RMSE between Corman et al 2023 data set and the output from the Droop model.

The Droop model does a garbage job at modelling GPP even with the "best scenario" parameters. Either the grid search didn't work or there are some problems with the model (I think it is the former; the models work but not for what we are trying to do here...)

```{r compare output of best droop model and real world data, dpi = 500, fig.width=13, fig.height=5}

best.run.droop.plt1 <- best.run.droop %>%
  ggplot() + 
  geom_point(aes(GPP, A1, col = log(TP_load)), size = 2.5) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", lwd = 1) + 
  labs(x = expression("Measured GPP mg C L"^-1 ), 
       y = expression("Modelled GPP mg C m"^-1), 
       col = "log(TP load mg m"^-3 ~ ")") 

best.run.droop.plt2 <- best.run.droop %>%
  ggplot() + 
  geom_point(aes(TN_load, A1, col = GPP), size = 2.5) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", lwd = 1) + 
  labs(y = expression("Modelled GPP mg C L"^-1 ), 
       x = expression("TN load mg m"^-3),
       col = expression("Measured GPP mg C m"^-1)) 

best.run.droop.plt3 <- best.run.droop %>%
  ggplot() + 
  geom_point(aes(TP_load, A1, col = GPP), size = 2.5) + 
  geom_abline(slope = 1, intercept = 0, lty = "dashed", lwd = 1) + 
  labs(y = expression("Modelled GPP mg C L"^-1 ), 
       x = expression("TP load mg m"^-3),
       col = expression("Measured GPP mg C m"^-1)) 

best.run.droop.plt1 + best.run.droop.plt2 + best.run.droop.plt3 + plot_layout(ncol = 3)

# some stats for text
#summary(lm(GPP ~ A1, data =best.run.droop))
#cor.test(best.run.droop$A1, best.run.droop$GPP)

```
